<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sql on Alfonso Subiotto</title><link>http://asubiotto.com/tags/sql/</link><description>Recent content in Sql on Alfonso Subiotto</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 31 Oct 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://asubiotto.com/tags/sql/index.xml" rel="self" type="application/rss+xml"/><item><title>How We Built a Vectorized Execution Engine</title><link>http://asubiotto.com/writing/how-we-built-vectorized-execution-engine/</link><pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate><guid>http://asubiotto.com/writing/how-we-built-vectorized-execution-engine/</guid><description>&lt;p>CockroachDB is an &lt;a href="https://en.wikipedia.org/wiki/Online_transaction_processing">OLTP&lt;/a> database, specialized for serving high-throughput queries that read or write a small number of rows. As we gained more usage, we found that customers werenâ€™t getting the performance they expected from analytic queries that read a lot of rows, like large scans, joins, or aggregations. In April 2018, we started to seriously investigate how to improve the performance of these types of queries in CockroachDB, and began working on a new SQL execution engine. In this blog post, we use example code to discuss how we built the new engine and why it results in up to a 4x speed improvement on an industry-standard benchmark.&lt;/p></description></item></channel></rss>